#!/usr/bin/env bash
# Copyright (c) Guangsheng Bao.
# Modified by Fan Huang.
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.


# setup the environment
echo `date`, Setup the environment ...
set -e  # exit if error

# parser.add_argument('--cache_dir', type=str, default="/home/fanhuan/cache")

# dataset folder, the data was generated by three jupyter notebooks
exp_path=../datasets/
data_path=$exp_path/full-dataset-ensemble-len-better
res_path=$exp_path/full-dataset-ensemble-len-better/results
mkdir -p $exp_path $data_path $res_path

datasets="xsum squad writing"
ensemble_approach="4-one-token-fast-gpu 4-two-token-fast-gpu 4-three-token-fast-gpu 4-four-token-fast-gpu 4-five-token-fast-gpu 4-random-token-fast-gpu 4-sentence-fast-gpu"

# White-box Setting
echo `date`, Evaluate models in the white-box setting:

# evaluate Fast-DetectGPT on un-filtered settings
for D in $datasets; do
  for M in $ensemble_approach; do
    echo `date`, Evaluating Fast-DetectGPT on ${D}_${M} ...
    scoring_models="gpt-neo-2.7B"
    python scripts/fast_detect_gpt.py --reference_model_name $scoring_models --scoring_model_name $scoring_models --dataset $D \
                          --dataset_file $data_path/${D}_${M} --output_file $res_path/${D}_${M}  --cache_dir /home/fanhuan/cache

    # echo `date`, Evaluating baseline methods on ${D}_${M} ...
    # python scripts/baselines.py --scoring_model_name $M --dataset $D \
    #                       --dataset_file $data_path/${D}_${M} --output_file $res_path/${D}_${M}  --cache_dir /home/fanhuan/cache
  done
done